{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11c5c8a1",
   "metadata": {},
   "source": [
    "# Whisky Project\n",
    "\n",
    "## 2. Data Exploration and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a434a0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jamie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jamie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\jamie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\jamie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>name</th>\n",
       "      <th>username</th>\n",
       "      <th>link</th>\n",
       "      <th>rating</th>\n",
       "      <th>region</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "      <th>review</th>\n",
       "      <th>reviewlength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27234</th>\n",
       "      <td>6/10/2015 21:42:28</td>\n",
       "      <td>Laphroaig 10 Cask Strength Batch 005</td>\n",
       "      <td>KaiForceOne</td>\n",
       "      <td>http://www.reddit.com/r/Scotch/comments/39dwmv...</td>\n",
       "      <td>93</td>\n",
       "      <td>Islay</td>\n",
       "      <td>NaN</td>\n",
       "      <td>06/10/15</td>\n",
       "      <td>*Archived 6/10/15 @ 9:45PM CST*\\n\\nFollowing a...</td>\n",
       "      <td>6617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23416</th>\n",
       "      <td>6/10/2015 16:14:44</td>\n",
       "      <td>Inchgower 33 1980 Malts of Scotland</td>\n",
       "      <td>Seienshin</td>\n",
       "      <td>http://www.reddit.com/r/Scotch/comments/394zu2...</td>\n",
       "      <td>97</td>\n",
       "      <td>Speyside</td>\n",
       "      <td>NaN</td>\n",
       "      <td>06/09/15</td>\n",
       "      <td>Hello Scotchit, SeienShin here! It has been a ...</td>\n",
       "      <td>3625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34129</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Pittyvaich 28 Special Release 2018</td>\n",
       "      <td>b1uepenguin</td>\n",
       "      <td>https://www.reddit.com/r/Scotch/comments/po8rs...</td>\n",
       "      <td>90</td>\n",
       "      <td>Speyside</td>\n",
       "      <td>NaN</td>\n",
       "      <td>09/14/21</td>\n",
       "      <td>*Scotch Review #450\\tWhisky Network Review #52...</td>\n",
       "      <td>2283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                timestamp                                  name     username  \\\n",
       "27234  6/10/2015 21:42:28  Laphroaig 10 Cask Strength Batch 005  KaiForceOne   \n",
       "23416  6/10/2015 16:14:44   Inchgower 33 1980 Malts of Scotland    Seienshin   \n",
       "34129                 NaN    Pittyvaich 28 Special Release 2018  b1uepenguin   \n",
       "\n",
       "                                                    link rating    region  \\\n",
       "27234  http://www.reddit.com/r/Scotch/comments/39dwmv...     93     Islay   \n",
       "23416  http://www.reddit.com/r/Scotch/comments/394zu2...     97  Speyside   \n",
       "34129  https://www.reddit.com/r/Scotch/comments/po8rs...     90  Speyside   \n",
       "\n",
       "      price      date                                             review  \\\n",
       "27234   NaN  06/10/15  *Archived 6/10/15 @ 9:45PM CST*\\n\\nFollowing a...   \n",
       "23416   NaN  06/09/15  Hello Scotchit, SeienShin here! It has been a ...   \n",
       "34129   NaN  09/14/21  *Scotch Review #450\\tWhisky Network Review #52...   \n",
       "\n",
       "       reviewlength  \n",
       "27234          6617  \n",
       "23416          3625  \n",
       "34129          2283  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import scipy\n",
    "from fuzzywuzzy import process\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('words')\n",
    "nltk.download('omw-1.4')\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "df = pd.read_csv('./data/gathering_complete.csv', index_col = 'Unnamed: 0')\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba228a0",
   "metadata": {},
   "source": [
    "### Initial Approach\n",
    "\n",
    "My idea for manipulating these data is to use RegEx to extract the specific adjectives used in the reviews to describe the whiskies. These are the regex expressions I'll need to extract out the tasting notes for nose, palate/taste, and finish respectively. \n",
    "\n",
    "    r\"(?:[Nn]ose)[^\\n]+\"\n",
    "    r\"(?:[Pp]alate)[^\\n]+|(?:[Tt]aste)[^\\n]+\"\n",
    "    r\"(?:[Ff]inish)[^\\n]+\"\n",
    "    \n",
    "The plan is to create a whisky by adjective matrix that looks something like this:\n",
    "\n",
    "|   | Nose_vanilla  | Nose_honey  | ...  | Palate_woody  | Palate_cherry  | ...  | Finish_dry | ... |\n",
    "|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|\n",
    "| Aberlour   | 1  | 0  | ...  | 0  | 1  | ...  | 0  | ... |\n",
    "| Glenlivet  |  0 |  1 | .. |  0 | 0  | ... | 0  | ...| \n",
    "| Glenfarclas  | 0  | 0  | ...  | 0  | 1  | ...  | 1  | ...|\n",
    "| Macallan  | 1  | 0  | ...  | 0  | 0  | ...  | 0  |...|\n",
    "| ...  | ...   | ...  | ...  | ...  | ...  | ...  | ...  |...|\n",
    "\n",
    "Alternatively, I could try counting the number of mentions of each tasting note instead, or make the matrix a matter of relative frequency of the tasting note by dividing by the number of reviews. \n",
    "\n",
    "I'll try disambiguating the nose, palate and finish first of all, and then try it where it's all lumped together. It's probably also worth trying a more general machine learning approach to the entire review, rather than trying to pick out individual adjectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95c3d4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Review #3: The Glendronach 'Original' - Aged 12 years.*\n",
      "\n",
      "**Edit/Warning:** This review is a bit long winded, I'm aware, but I'm not sorry ;) There is so much to discover underneath this cork that I feel obligated to do it justice. Anything less and I'd be doing you a disservice. Regardless, I hope you'll read and enjoy it, and if not that's okay, I'll sum it up for you here...This is a damn fine adventure of a whisky. Drink it. But seriously, if a lengthy review is going to upset you, I don't want that and this may not be to your taste. \n",
      "\n",
      "**The \"blah blah blah\":** Ahh, The Glendronach 12 Original, an absolute testament to the magnificence a properly executed sherry can provide. The firm spirit hailing from the Dronach Burn is just perfectly suited for a happy, full, and well-spent life in sherried oak. \n",
      "\n",
      "Part PX, part Oloroso, full epic journey.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "**Cost:** I paid $80, but I've never seen it go for such a high cost, tariffs maybe? Historically I've paid around $45-$60. However, this was the only bottle I could find in my area. So be it, no regrets, but I'm writing this review assuming it's meant to be sold at $60, or thereabouts, and that I just caught a bad vendor or something.\n",
      "\n",
      "**Age:** 12 years.\n",
      "\n",
      "**ABV:** 43%\n",
      "\n",
      "**NCF/Natural Color**\n",
      "\n",
      "**Neat Pour - Snifter - 15 minutes rested**\n",
      "\n",
      "**Nose:** Literally smells like the month of October in northern Michigan. October is my favorite month and this dram clearly knows it, as I'm being personally catered to here.\n",
      "It's as if this dram exists solely because I exist. Bold, sweet sherry accompanied by a siren song of creamy, silky vanilla, sung from a sea of soft, subtle wood spices. Ginger, nutmeg, done so with hardly a hint of bitterness.\n",
      "\n",
      "**Palate:** Big, tall, full mouth feel. This is the finest of silk, if I had to guess I'd say the thread count is around 7.5 million. **Sherry. Forward.** Oak tannin and wood spices from the nose are presenting as comfortably warm, not quite bitter, but close, so as to do a fine job of keeping the sherried sweetness in check.\n",
      "*Balance*, such that if this dram were human, it would be able to walk a tight rope made of dental floss. *Over the friggin' Grand Canyon*.\n",
      "So many fruits here to pick out, largely dried and dark. Plum, raisins, cherries. There's also an interesting Earthy note that's hard to pin down, I want to say tobacco (that's Earthy right?) Truly unique. \n",
      "This is perfectly and wonderfully complex, so much to find. Search it all out, dig around and this dram will reward you for your efforts. Over and over again.\n",
      "\n",
      "**Finish:** Not entirely long, but damn, it's so good I wish it were. That's depressing. \n",
      "It is definitely full though. Wood tannin lingers and dries and yet *still* manages to stay just this side of bitter, an incredible feat to be sure, but I do find myself wanting it to break through that threshold into bitter territory, if just slightly. I think it should boldly take that leap for several reasons, the most notable being that it feels like a natural progression after slowly building on the bitterness through the nose & palate; a bitter spike here may be quite liberating; might also help to lengthen the overall finish.\n",
      "With that said, the liquid is somehow still rewarding you at this point, with brand new flavors to discover. Like, wherever did this vaguely roasted nutty note come from?\n",
      "Finally, you can find the malt disguised as a sweet and sugary breakfast cereal. If you know where to look you can find some marshmallow.\n",
      "All of this unfolds quite quickly, and some-crazy-how it is not jarring, rather, it's sequential. \n",
      "Yep...I'm going back in for another sip...and another..\n",
      "\n",
      "...and another....\n",
      "\n",
      "I'll be here a while, don't wait up.\n",
      "\n",
      "**Score: 88/100**\n",
      "\n",
      "**Wrap-up:** This bad lad would have been a shoe-in for a ranking in the 90's if the finish were only longer. But alas, it comes and goes swiftly. That may be, but it makes damn good use of the short and special time you have with it. We're dealing with a professional, nay, an *expert* in the field of complexity and balance here. I'm left amazed by the way this dram weaves so many flavors together, while keeping in perfect harmony. \n",
      "\n",
      "**Positively orchestral;** *Gracefully utilizing an array of distinguishable instruments to perform one song; to tell one story, 12 long years in the making.*\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " **Ranking Scale**\n",
      "\n",
      "**96-100: Impeccable.** - Without a fault or flaw. Extremely rare.\n",
      "\n",
      "**90-95: All-time favorite.** - Daily driver. Enjoys permanent residence in the rotation.\n",
      "\n",
      "**85-89: Truly outstanding.** - Memorable by unique complexity and development; quickly identified in a blind.\n",
      "\n",
      "**80-84: Above average** - Highly enjoyable, a great entry level dram. Not challenging, but bold and defined.\n",
      "\n",
      "**75-79: Tier-2 Average** - No distracting issues, but severely lacking in character and profile.\n",
      "\n",
      "**70-74: Tier-1 Average** - One, possibly two, minor issue(s) noted in one category.\n",
      "\n",
      "**60-69: Below average** - Notable and objective issues found in at least two of the three tasting categories.\n",
      "\n",
      "**40-59: Poor Quality** - Not to be consumed neat. Copius amounts of ice, water or Cola required.\n",
      "\n",
      "**10-39: Undrinkable** - Not even ice or soda can fix this. Just cook with it.\n",
      "\n",
      "**0-9: Drain Cleaner** (A rarity)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " extracted text for the palate/taste is \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ['taste. ', \"Palate:** Big, tall, full mouth feel. This is the finest of silk, if I had to guess I'd say the thread count is around 7.5 million. **Sherry. Forward.** Oak tannin and wood spices from the nose are presenting as comfortably warm, not quite bitter, but close, so as to do a fine job of keeping the sherried sweetness in check.\", 'palate; a bitter spike here may be quite liberating; might also help to lengthen the overall finish.']\n"
     ]
    }
   ],
   "source": [
    "# Testing out regex - extracting palate \n",
    "i = np.random.randint(0,40000)\n",
    "text = df.iloc[i,:]['review']\n",
    "extracted = re.findall(r\"(?:[Pp]alate)[^\\n]+|(?:[Tt]aste)[^\\n]+\", text)\n",
    "print(text)\n",
    "print('\\n\\n\\n\\n\\n extracted text for the palate/taste is \\n\\n\\n\\n\\n', extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "341e6ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>name</th>\n",
       "      <th>username</th>\n",
       "      <th>link</th>\n",
       "      <th>rating</th>\n",
       "      <th>region</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "      <th>review</th>\n",
       "      <th>reviewlength</th>\n",
       "      <th>nose</th>\n",
       "      <th>palate</th>\n",
       "      <th>finish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8474</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Bruichladdich Black Art 7.1</td>\n",
       "      <td>TOModera</td>\n",
       "      <td>https://www.reddit.com/r/Scotch/comments/p6q40...</td>\n",
       "      <td>82</td>\n",
       "      <td>Islay</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/18/21</td>\n",
       "      <td>If you’re a hobby person (aka someone who’s ac...</td>\n",
       "      <td>9845</td>\n",
       "      <td>[Nose: Lemon, cherry, hot cross buns, brine, t...</td>\n",
       "      <td>[taste, shall we?, tasters than myself stating...</td>\n",
       "      <td>[Finish: Cinnamon, plum, mesquite, brown sugar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25398</th>\n",
       "      <td>10/8/2014 14:58:30</td>\n",
       "      <td>Kilchoman 100% Islay 3rd Edition</td>\n",
       "      <td>Spardocus</td>\n",
       "      <td>http://www.reddit.com/r/Scotch/comments/2iouiz...</td>\n",
       "      <td></td>\n",
       "      <td>Islay</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/8/2014</td>\n",
       "      <td>Greetings Scotchit, after lurking around for o...</td>\n",
       "      <td>2155</td>\n",
       "      <td>[Nose: This is the reason I decided to come ou...</td>\n",
       "      <td>[Taste: A wall of smoke washes over the front,...</td>\n",
       "      <td>[Finish: Long, smooth finish with musty peat a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40277</th>\n",
       "      <td>6/23/2014 9:09:44</td>\n",
       "      <td>Wild Turkey Rare Breed</td>\n",
       "      <td>gaxkang</td>\n",
       "      <td>http://www.reddit.com/r/bourbon/comments/28rd3...</td>\n",
       "      <td>86</td>\n",
       "      <td>Bourbon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/22/2014</td>\n",
       "      <td>Bourbon review #19: Mystery dram #12 from /u/v...</td>\n",
       "      <td>769</td>\n",
       "      <td>[Nose: oranges, bananas, vanilla, cream, cinna...</td>\n",
       "      <td>[Taste: hot, rye, bananas, lime, lemons, cinna...</td>\n",
       "      <td>[Finish: hot, salty, spice, sweet]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                timestamp                              name   username  \\\n",
       "8474                  NaN       Bruichladdich Black Art 7.1   TOModera   \n",
       "25398  10/8/2014 14:58:30  Kilchoman 100% Islay 3rd Edition  Spardocus   \n",
       "40277   6/23/2014 9:09:44            Wild Turkey Rare Breed    gaxkang   \n",
       "\n",
       "                                                    link rating   region  \\\n",
       "8474   https://www.reddit.com/r/Scotch/comments/p6q40...     82    Islay   \n",
       "25398  http://www.reddit.com/r/Scotch/comments/2iouiz...           Islay   \n",
       "40277  http://www.reddit.com/r/bourbon/comments/28rd3...     86  Bourbon   \n",
       "\n",
       "      price       date                                             review  \\\n",
       "8474    NaN   08/18/21  If you’re a hobby person (aka someone who’s ac...   \n",
       "25398   NaN  10/8/2014  Greetings Scotchit, after lurking around for o...   \n",
       "40277   NaN  6/22/2014  Bourbon review #19: Mystery dram #12 from /u/v...   \n",
       "\n",
       "       reviewlength                                               nose  \\\n",
       "8474           9845  [Nose: Lemon, cherry, hot cross buns, brine, t...   \n",
       "25398          2155  [Nose: This is the reason I decided to come ou...   \n",
       "40277           769  [Nose: oranges, bananas, vanilla, cream, cinna...   \n",
       "\n",
       "                                                  palate  \\\n",
       "8474   [taste, shall we?, tasters than myself stating...   \n",
       "25398  [Taste: A wall of smoke washes over the front,...   \n",
       "40277  [Taste: hot, rye, bananas, lime, lemons, cinna...   \n",
       "\n",
       "                                                  finish  \n",
       "8474   [Finish: Cinnamon, plum, mesquite, brown sugar...  \n",
       "25398  [Finish: Long, smooth finish with musty peat a...  \n",
       "40277                 [Finish: hot, salty, spice, sweet]  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_nose(text):\n",
    "    try:\n",
    "        extract_text = re.findall(r\"(?:[Nn]ose)[^\\n]+\", text)\n",
    "        extract_text = [extract_text[i].replace(\"*\", \"\") \n",
    "         for i in range(len(extract_text))]\n",
    "    except:\n",
    "        extract_text = []\n",
    "    return extract_text\n",
    "\n",
    "def extract_palate(text):\n",
    "    try:\n",
    "        extract_text = re.findall(r\"(?:[Pp]alate)[^\\n]+|(?:[Tt]aste)[^\\n]+\", text)\n",
    "        extract_text = [extract_text[i].replace(\"*\", \"\") \n",
    "         for i in range(len(extract_text))]\n",
    "    except:\n",
    "        extract_text = []\n",
    "    return extract_text\n",
    "\n",
    "def extract_finish(text):\n",
    "    try:\n",
    "        extract_text = re.findall(r\"(?:[Ff]inish)[^\\n]+\", text)\n",
    "        extract_text = [extract_text[i].replace(\"*\", \"\") \n",
    "         for i in range(len(extract_text))]\n",
    "    except:\n",
    "        extract_text = []\n",
    "    return extract_text\n",
    "\n",
    "df['nose']=df['review'].apply(extract_nose)\n",
    "df['palate']=df['review'].apply(extract_palate)\n",
    "df['finish']=df['review'].apply(extract_finish)\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1784fd2",
   "metadata": {},
   "source": [
    "We noticed before that we had reviews that concerned several bottles of whisky at once, and now we're in a position to identify these reviews by counting the size of the lists we've just produced for nose, palate and finish. The modal case should be that every row has one of each, but there's bound to be some discrepancies, and that's what I'll now investigate..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e7a33f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['noselength']=df['nose'].apply(lambda x: len(x))\n",
    "df['palatelength']=df['palate'].apply(lambda x: len(x))\n",
    "df['finishlength']=df['finish'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "665de978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14393, 9097)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# more_than_2 is a list of the indices of rows that have 'nose', 'palate/taste', and 'finish'\n",
    "# all at least 2 times, indicating more than one review taking place in all likelihood.\n",
    "# exactly_one shows how many have one extracted bit for nose, palate and finish.\n",
    "\n",
    "more_than_2 = df[(df['noselength']>=2) & (df['palatelength']>=2) & (df['finishlength']>=2)].index.tolist()\n",
    "exactly_one = df[(df['noselength']==1) & (df['palatelength']==1) & (df['finishlength']==1)].index.tolist()\n",
    "\n",
    "len(more_than_2), len(exactly_one)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3382ec63",
   "metadata": {},
   "source": [
    "As you can see, we have a lot of multiple reviews and not many where things are unproblematically one item for nose, taste, and finish. And really I should have realised this earlier, because..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a834121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10168"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# duplicated is a list of all rows that have a link shared with another row\n",
    "\n",
    "duplicate_links_list = df[df['link'].duplicated()]['link'].tolist()\n",
    "duplicated = df[df['link'].isin(duplicate_links_list)].index.tolist()\n",
    "len(duplicated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76c7b199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8798, 5595, 1370)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The set of rows that are in both dataframes\n",
    "both = set(more_than_2) & set(duplicated)\n",
    "\n",
    "# The set of rows that are in more_than_2 but not in duplicated:\n",
    "more_only = set(more_than_2) - set(duplicated)\n",
    "\n",
    "# The set of rows that are in duplicated but not in more_than_2:\n",
    "duplicated_only = set(duplicated) - set(more_than_2)\n",
    "\n",
    "# Check - should add up to 10168+14393 = 24561 (it does)\n",
    "# len(more_only) + len(duplicated_only) + 2*len(both)\n",
    "\n",
    "len(both), len(more_only), len(duplicated_only)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bbef31",
   "metadata": {},
   "source": [
    "The good news here is that in the 'both' cases, we have 8798 rows where we have different whisky all with the same review text. What needs to happen here is merely that we need to split the text up and match each one with the correct whisky. I say 'merely' - that's probably not going to be that easy.\n",
    "\n",
    "But this means that I have some other cases - the 5595 'more_only' cases. This is where there are two references to taste, nose and finish in the text, but only one whisky. What is happening here is usually that the author has compiled different notes under drinking the whisky neat and drinking it with water. Since they're all valid tasting notes (adding water usually just helps to 'open up' the whisky), the solution here is to simply combine the notes.\n",
    "\n",
    "Finally, I have 1370 cases where there's duplicate reviews, but I haven't picked up on it by looking for 'nose', 'taste' and 'finish'. That's probably just that the review hasn't specifically broken out their review into nose, taste and finish, a problem that is affecting about 1/3 of my dataset. My plan at the moment is that, once I have compiled a matrix of all the adjectives I need, it will be a lot easier to go back into the reviews and simply search for those adjectives directly. It won't be as fine-grained as splitting them up into nose, taste, and finish, and it introduces more noise, so it may not be worth doing, but it's a possibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf802344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create copy of df to manipulate for the 8798 group\n",
    "df_both = df.loc[list(both), :].copy()\n",
    "\n",
    "# Sort by link\n",
    "df_both = df_both.sort_values('link')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28dbc841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a text file so I can browse through and see if I can figure out a way to \n",
    "# match the reviews\n",
    "\n",
    "def printfile(df, name):\n",
    "    '''\n",
    "    INPUTS:\n",
    "    df - pandas dataframe you want to print out\n",
    "    name - name you want to give the text file\n",
    "    OUTPUTS:\n",
    "    -\n",
    "    '''\n",
    "    with open('./data/' + name, 'w') as file:\n",
    "        for i in range((df.shape[0])):\n",
    "            try:\n",
    "                file.writelines('\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nIndex is ' + str(df.index[i]) + '\\n')\n",
    "                file.writelines('Name is ' + str(df.iloc[i,1]) + '\\n')\n",
    "                file.writelines('Review is ' + str(df.iloc[i,8]) + '\\n')\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "printfile(df_both, 'both.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab869746",
   "metadata": {},
   "source": [
    "Looking through the text file I've just created, it seems as though a good way to split up the reviews that will work for something like 80% of them is by splitting up the review whenever it encounters the '/10(0)' token. This always comes at the end of the review of the particular whisky. The only problem then is that I'll need to match the whisky to the review. This is not so simple, because the name in the 'name' column won't necessarily match exactly. Thus, I'll have to use a bit of 'fuzzy string matching' (using a module called 'fuzzywuzzy') so I'll be able to pick out the review that's most likely to correspond to the correct one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3822576d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting review into a list with various things as separators\n",
    "df_both['review'] = df_both['review'].str.split(r'/100|--|\\*\\*\\*|___|&nbsp')\n",
    "\n",
    "# Deleting small 'reviews' so that it doesn't confuse get_best_fit:\n",
    "def del_small_reviews(reviewlist):\n",
    "    '''\n",
    "    INPUTS:\n",
    "    reviewlist (list) - list of reviews\n",
    "    OUTPUTS:\n",
    "    newlist - reviews with the <100 character ones removed\n",
    "    '''\n",
    "    newlist=[]\n",
    "    for review in reviewlist:\n",
    "        if len(review)>50:\n",
    "            newlist.append(review)\n",
    "    return newlist\n",
    "\n",
    "df_both['review'] = df_both['review'].apply(del_small_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7676f10c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_best_fit(name, reviewlist):\n",
    "    '''\n",
    "    INPUTS:\n",
    "    name (string) - name of the whisky you're trying to identify the review for\n",
    "    reviewlist (list) - list of potential reviews you're matching it to\n",
    "    \n",
    "    OUTPUTS:\n",
    "    output (string) - best guess as to the review for that whisky\n",
    "    '''\n",
    "    bolded_name = r\"\\*\\*\" + re.escape(name) + r\"\\*\\*\" \n",
    "    bolded_match_list = []\n",
    "    unbolded_match_list = []\n",
    "\n",
    "    # Search for exact match on both unbolded and bolded name:\n",
    "    for review in reviewlist:\n",
    "        if re.search(bolded_name, review):\n",
    "            bolded_match_list.append(review)\n",
    "        if re.search(name, review):\n",
    "            unbolded_match_list.append(review)\n",
    "\n",
    "    # If there's only one exact match for bolded name, that's the review you want\n",
    "    if len(bolded_match_list)==1:\n",
    "        output = str(bolded_match_list[0])\n",
    "\n",
    "    # If there's more than one exact match, use fuzzywuzzy to get best match from the matches\n",
    "    elif len(bolded_match_list)>1:\n",
    "        output = str(process.extractOne(name, bolded_match_list)[0])\n",
    "\n",
    "    # If there's no exact matches...\n",
    "    else:\n",
    "        # If there's only one exact match for unbolded name, that's the review you want\n",
    "        if len(unbolded_match_list)==1:\n",
    "            output = str(unbolded_match_list[0])\n",
    "\n",
    "        # If there's more than one exact match, use fuzzywuzzy to get best match from the matches\n",
    "        elif len(unbolded_match_list)>1:\n",
    "            output = str(process.extractOne(name, unbolded_match_list)[0])\n",
    "\n",
    "        # If there's no matches on unbolded names either, just use fuzzywuzzy on original list:\n",
    "        else:\n",
    "            try:\n",
    "                output = str(process.extractOne(name, reviewlist)[0])\n",
    "            except:\n",
    "                output = reviewlist\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6883aa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seems to work. Run on the whole thing \n",
    "df_both['review'] = df_both.apply(lambda x: get_best_fit(x['name'], x['review']), axis=1)\n",
    "\n",
    "# Print out text file\n",
    "printfile(df_both, 'both2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f198dc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract nose, palate and finish from the updated review\n",
    "df_both['nose']=df_both['review'].apply(extract_nose)\n",
    "df_both['palate']=df_both['review'].apply(extract_palate)\n",
    "df_both['finish']=df_both['review'].apply(extract_finish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "957f1ba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1     3483\n",
       " 0     2514\n",
       " 2     1539\n",
       " 3      569\n",
       " 4      305\n",
       " 5      153\n",
       " 6       84\n",
       " 10      43\n",
       " 8       41\n",
       " 7       38\n",
       " 12      14\n",
       " 9       10\n",
       " 11       5\n",
       " Name: noselength, dtype: int64,\n",
       " 1     3148\n",
       " 0     2327\n",
       " 2     1697\n",
       " 3      639\n",
       " 4      391\n",
       " 6      163\n",
       " 5      151\n",
       " 7       72\n",
       " 8       55\n",
       " 9       54\n",
       " 10      45\n",
       " 12      21\n",
       " 11      18\n",
       " 16      10\n",
       " 23       7\n",
       " Name: palatelength, dtype: int64,\n",
       " 1     3234\n",
       " 0     2495\n",
       " 2     1635\n",
       " 3      686\n",
       " 4      292\n",
       " 5      159\n",
       " 6      103\n",
       " 7       70\n",
       " 8       37\n",
       " 11      30\n",
       " 12      25\n",
       " 9       17\n",
       " 10      10\n",
       " 13       5\n",
       " Name: finishlength, dtype: int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-do finding number of instances of 'nose', 'taste'/'palate', and 'finish' in the review\n",
    "df_both['noselength']=df_both['nose'].apply(lambda x: len(x))\n",
    "df_both['palatelength']=df_both['palate'].apply(lambda x: len(x))\n",
    "df_both['finishlength']=df_both['finish'].apply(lambda x: len(x))\n",
    "\n",
    "# Get counts\n",
    "(df_both['noselength'].value_counts(), \n",
    "df_both['palatelength'].value_counts(), \n",
    " df_both['finishlength'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f645563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of problems still:\n",
    "df_both_prob = df_both[(df_both['noselength']>1) & (df_both['palatelength']>1) & (df_both['finishlength']>1)].index.tolist()\n",
    "df_zeroes = df_both[(df_both['noselength']==0) & (df_both['palatelength']==0) & (df_both['finishlength']==0)].index.tolist()\n",
    "                                                  \n",
    "# As a dataframe\n",
    "df_probs = df_both.loc[df_both_prob,:].sort_values('link')\n",
    "df_zeroes = df_both.loc[df_zeroes,:].sort_values('link')\n",
    "\n",
    "# Print the reviews\n",
    "printfile(df_probs, 'probs.txt')\n",
    "printfile(df_zeroes, 'zeroes.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2e2f923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(863, 968)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_probs['link'].unique()), len(df_zeroes['link'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111d072c",
   "metadata": {},
   "source": [
    "As you can see, there's still lots of problems, but there's just no easy way of cutting up multiple reviews and then identifying the correct one. I'll just have to take the ones that give me exactly one match for nose, taste, and finish, and leave the others, I think. Otherwise, I will have to spend literal weeks trying to get these reviews into the right shape, and that simply isn't a good use of time. At this stage, I'm not even 100% sure that there is any utility in the project at all.\n",
    "\n",
    "--------------\n",
    "\n",
    "### New Approach\n",
    "\n",
    "A different approach was needed at this point. What I decided to do was create functions that automate the process of applying different rules to rows in 'review' column to separate them into a list of chunks of text that might correspond to individual whiskies, and then progressively take off the rows where I'm relatively confident I've got the right one. \n",
    "\n",
    "So, first of all I need a function that splits the data frame into two, keeping rows that have nose, palate, finish = 1. Idea is that I'm going to progressively strengthen the rules on splitting up the 'review' column until I get as many hits as I can.\n",
    "\n",
    "Note that I've also got a small helper function storage_rule_default() that defines the rule I'm using to decide whether to add a row to my store of successful hits (dfstore). I'll talk more about that in a second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7bb3fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31487, (9097, 16))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dfstore - dataframe that will store rows that have 1 string for 'nose', 'palate', and \n",
    "# for 'finish'\n",
    "dfstore = df[(df['noselength']==1) & (df['palatelength']==1) & (df['finishlength']==1)].copy()\n",
    "\n",
    "# default logical rule for what gets stored in dfstore\n",
    "def storage_rule_default(df):\n",
    "    return df[(df['noselength']==1) & (df['palatelength']==1) & (df['finishlength']==1)]\n",
    "\n",
    "def filter_off_singular_reviews(dfnew, storage_rule=storage_rule_default, dfstore=dfstore):\n",
    "    '''\n",
    "    INPUTS:\n",
    "    dfnew - pandas dataframe containing potential new rows to add to the store of good reviews.\n",
    "    storage_rule - name of function that slices dataframe to get rows that should get stored.\n",
    "    dfstore - dataframe store of singular reviews (i.e. where nose, palate and finish are all \n",
    "            just lists of length one)\n",
    "    OUTPUTS:\n",
    "    dfstore - same as above\n",
    "    remain_idx - indices of the remaining rows\n",
    "    '''\n",
    "    # Make copy of dataframe\n",
    "    df = dfnew.copy()\n",
    "    \n",
    "    # Extract nose, palate and finish from the dataframe\n",
    "    df['nose']=df['review'].apply(extract_nose)\n",
    "    df['palate']=df['review'].apply(extract_palate)\n",
    "    df['finish']=df['review'].apply(extract_finish)\n",
    "    \n",
    "    # Finding number of instances of 'nose', 'taste'/'palate', and 'finish' in the review\n",
    "    df['noselength']=df['nose'].apply(lambda x: len(x))\n",
    "    df['palatelength']=df['palate'].apply(lambda x: len(x))\n",
    "    df['finishlength']=df['finish'].apply(lambda x: len(x))\n",
    "\n",
    "    # Update dfstore and dfremain\n",
    "    dfadd = storage_rule(df)\n",
    "    remain_idx = list(set(df.index) - set(dfadd.index))\n",
    "    dfadd = dfadd.loc[list(set(dfadd.index)-set(dfstore.index)),:]\n",
    "    dfstore = pd.concat([dfstore, dfadd], axis=0)\n",
    "\n",
    "    return remain_idx, dfstore\n",
    "\n",
    "# Run df through - dfstore should remain unchanged here\n",
    "remain_idx, dfstore = filter_off_singular_reviews(df)\n",
    "len(remain_idx), dfstore.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f3e542",
   "metadata": {},
   "source": [
    "Now I need a function that applies in turn the different values I might use to separate out the 'review' text into a list, and then sends the results to get filtered off. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04d1820f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_list = [\n",
    "    r'___',\n",
    "    r'--',\n",
    "    r'##',\n",
    "    r'~~~',\n",
    "    r'\\*\\*\\*',\n",
    "    r'&nbsp;',\n",
    "    r'/100',\n",
    "    r'/10',\n",
    "    r'Rating',\n",
    "    r'Score',\n",
    "    r'Overall',\n",
    "    r'Total',\n",
    "    r'Review',\n",
    "    r'Conclusion',\n",
    "]\n",
    "\n",
    "def get_singular_reviews(rules_list, storage_rule=storage_rule_default, \n",
    "                         remain_idx=remain_idx, dfstore=dfstore):\n",
    "    '''\n",
    "    INPUTS:\n",
    "    rules_list - list of the expressions to be fed into str.split to split up the \n",
    "    'review' column and then match the right review. \n",
    "    storage_rule - name of function that slices dataframe to get rows that should get stored.\n",
    "    dfstore - dataframe of rows where we're pretty confident we've got the right tasting notes.\n",
    "    remain_idx - indices of the rows from the original df not used.\n",
    "    OUTPUTS:\n",
    "    dfstore - dataframe of rows where we're pretty confident we've got the right tasting notes.\n",
    "    remain_idx - indices of the rows from the original df not used.\n",
    "    '''\n",
    "    \n",
    "    # Apply the rule for splitting the review up\n",
    "    for rule in rules_list:\n",
    "        # Keep track of size of dfstore\n",
    "        numrows_old = dfstore.shape[0]\n",
    "\n",
    "        # Create a df, dfremain to manipulate \n",
    "        dfremain = df.loc[remain_idx,:].copy()\n",
    "\n",
    "        # Applying the rule to split the review\n",
    "        print('Applying the rule {} ...'.format(rule))\n",
    "        dfremain['review'] = dfremain['review'].str.split(rule)\n",
    "\n",
    "        # Delete the small items in the list of 'reviews' so that it doesn't confuse get_best_fit:\n",
    "        dfremain['review'] = dfremain['review'].apply(del_small_reviews)\n",
    "\n",
    "        # Apply get_best_fit to the list of 'reviews' and extract 'nose', etc.\n",
    "        dfremain['review'] = dfremain.apply(lambda x: get_best_fit(x['name'], x['review']), axis=1)\n",
    "\n",
    "        # Drop any rows with null entries for 'nose', etc.\n",
    "        dfremain[['nose', 'palate', 'finish']] = dfremain[['nose', 'palate', 'finish']].dropna()\n",
    "\n",
    "        # Filter off rows with singular reviews for nose, etc.\n",
    "        remain_idx, dfstore = filter_off_singular_reviews(dfremain, storage_rule, dfstore)\n",
    "        print(\"{} rows added.\".format(dfstore.shape[0]-numrows_old))\n",
    "        \n",
    "    return remain_idx, dfstore\n",
    "\n",
    "# Commented out because time-consuming and results are eventually stored and reloaded anyway.\n",
    "\n",
    "#remain_idx, dfstore = get_singular_reviews(rules_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9bb1efc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commented out because time-consuming and results are eventually stored and reloaded anyway.\n",
    "\n",
    "# Print the reviews\n",
    "#printfile(df.loc[remain_idx,:], 'probs.txt')\n",
    "#printfile(dfstore, 'success.txt')\n",
    "#len(remain_idx), dfstore.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5658eacb",
   "metadata": {},
   "source": [
    "Looking through the probs.txt, there's lots of cases where I've actually matched the review just fine, but the rule I'm using for keeping it (i.e. that the length of the lists for nose, palate, and finish must all be 1, is simply too strong). Thus, what I'll do is run the rules list splitting up the reviews again, but this time I'll first allow one of 'taste'/'palate', 'nose', or 'finish' to have a count of 2 to get stored in dfstore, and then I'll run it so that I'll allow the sum of the counts of the lengths to be 3-5 (provided they're all still 1+). So (1, 0, 3), say would be ruled out, as would (2, 2, 2), but (2, 1, 2) or (1, 2, 1) would be fine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d10010ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use first looser rule that allows one count to be 2:\n",
    "def storage_rule_one_count_can_be_two(df):\n",
    "    return df[(df['noselength']>=1) & \n",
    "               (df['palatelength']>=1) & \n",
    "               (df['finishlength']>=1) &\n",
    "               (df['noselength']+df['palatelength']+df['finishlength']<=4)]\n",
    "\n",
    "#remain_idx, dfstore = get_singular_reviews(rules_list, \n",
    "#                                           storage_rule=storage_rule_one_count_can_be_two)\n",
    "\n",
    "\n",
    "# Use second looser rule that allows two counts to be 2:\n",
    "def storage_rule_two_counts_can_be_two(df):\n",
    "    return df[(df['noselength']>=1) & \n",
    "               (df['palatelength']>=1) & \n",
    "               (df['finishlength']>=1) &\n",
    "               (df['noselength']+df['palatelength']+df['finishlength']<=5)]\n",
    "\n",
    "#remain_idx, dfstore = get_singular_reviews(rules_list, \n",
    "#                                           storage_rule=storage_rule_two_counts_can_be_two)\n",
    "\n",
    "# Print the reviews\n",
    "#printfile(df.loc[remain_idx,:], 'probs.txt')\n",
    "#printfile(dfstore, 'success.txt')\n",
    "#len(remain_idx), dfstore.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5eece1ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31205, 6)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dfstore.to_csv('./data/singular_reviews.csv')\n",
    "\n",
    "# Reopening as df, dropping unneeded columns\n",
    "df = pd.read_csv('./data/singular_reviews.csv', index_col = 'Unnamed: 0')\n",
    "df = df[['name', 'rating', 'region', 'nose', 'palate', 'finish']]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8754dc6",
   "metadata": {},
   "source": [
    "I'm relatively happy with that, to be honest. We've got a good amount of data to work with now - about 3/4 of the original dataset. I'm sure I could improve it, but I'm a week in and time is a factor, and it's a case of diminishing marginal returns. Looking through the success.txt, there's some noise in there too because often I'm best-guessing which cut-up review matches which row, but it doesn't appear to be that common. In general, we do seem to be picking out the right bit of the text and matching it to the right whisky.\n",
    "\n",
    "Handily, saving and reloading the file from .csv has also flattened the nose, palate, and finish columns to strings, which is something I'd have needed to do anyway. I can now proceed to start extracting word lemmas from the notes. \n",
    "\n",
    "Another issue I have to address is the degree of specificity with the whisky names. In fact, I'll start with this. Clearly I'll need to use some grouping because..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b438d1c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11194"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['name'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6139ceff",
   "metadata": {},
   "source": [
    "12000 distinct whiskies is simply too much. The first thing to do is to separate out the brand. I first tried doing this all at once with a big brand list, but that was computationally horrendous, so I had to break up the data into distinct sets and do it region by region. So what follows is me going through the main regions (stopping short of Sweden) and picking out the main brands of whisky, then matching a 'brand' column from the 'name' for whiskies in that region, and collating them all together into df_collated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e613e21c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Speyside       5872\n",
       "Islay          5832\n",
       "Bourbon        5283\n",
       "Highlands      4106\n",
       "Islands        2126\n",
       "Blend          1656\n",
       "Rye            1308\n",
       "Campbeltown    1156\n",
       "Lowlands        587\n",
       "Canada          571\n",
       "America         564\n",
       "Ireland         543\n",
       "Japan           504\n",
       "India           277\n",
       "Taiwan          173\n",
       "Australia       130\n",
       "Sweden           63\n",
       "France           58\n",
       "Wheat            34\n",
       "Netherlands      33\n",
       "Name: region, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get list of main regions\n",
    "df['region'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f09487e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function that matches the brand of whisky to the best one in the list and checks\n",
    "# that the brand name is at least present in the 'name' column.\n",
    "\n",
    "def get_match(string, matchlist):\n",
    "    string = string.replace(\".\", \"\")\n",
    "    string = string.replace(\"\\'\", \"\")\n",
    "    output = str(process.extractOne(string, matchlist)[0])\n",
    "    if re.search(output.lower(), string.lower()): \n",
    "        pass\n",
    "    else:\n",
    "        output = np.NaN\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "19edd210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a smaller dataframe just to get things to work for the Speyside whiskies\n",
    "df_speyside = df[df['region'].str.lower()=='speyside'].copy()\n",
    "df_speyside['region'] = 'Speyside'\n",
    "\n",
    "# list of whiskies in the Speyside region:\n",
    "speyside_list = ['Aberlour', 'Allt-A-Bhainne', 'Ardmore', 'Auchroisk', 'Aultmore', \n",
    "                 'Balmenach','Balvenie', 'BenRiach', 'Benrinnes', 'Benromach', 'Braeval', \n",
    "                 'Caperdonich', 'Cardhu', 'Coleburn', 'Convalmore', 'Cragganmore', \n",
    "                 'Craigellachie', 'Dailuaine', 'Dallas Dhu', 'Dufftown', 'Glen Elgin', \n",
    "                 'Glen Grant', 'Glen Keith', 'Glen Moray', 'Glen Spey', 'Glenallachie', \n",
    "                 'Glenburgie', 'Glendullan', 'Glenfarclas', 'Glenfiddich', 'Glenlivet', \n",
    "                 'Glenlossie', 'Glenrothes', 'Glentauchers', 'Imperial', 'Inchgower',\n",
    "                 'Knockando', 'Linkwood', 'Longmorn', 'Macallan', 'Mannochmore', \n",
    "                 'Miltonduff', 'Mortlach', 'Portknockie', 'Pittyvaich', 'Speyburn',\n",
    "                 'Strathisla', 'Strathmill', 'Tamdhu', 'Tamnavulin', 'Tomintoul', 'Tormore',\n",
    "                'Lismore', 'Stronachie','Old Ballantruan', 'Glenglassaugh']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7125668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a smaller dataframe just to get things to work for the Islay whiskies\n",
    "df_islay = df[df['region'].str.lower()=='islay'].copy()\n",
    "df_islay['region']='Islay'\n",
    "\n",
    "\n",
    "islay_list = ['Ardbeg', 'Bowmore', 'Bruichladdich', 'Bunnahabhain', 'Caol Ila',\n",
    "              'Finlaggan', 'Islay Storm', 'Kilchoman', 'Lagavulin', 'Laphroaig',\n",
    "              'Macleods', 'Octomore', 'Port Askaig', 'Port Charlotte', 'Port Ellen',\n",
    "              'Ileach']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "77258d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a smaller dataframe just to get things to work for the Bourbon whiskies\n",
    "df_bourbon = df[df['region'].str.lower()=='bourbon'].copy()\n",
    "df_bourbon['region']='Bourbon'\n",
    "\n",
    "# List of Bourbon whiskies to use\n",
    "bourbon_list = ['Old Weller Antique', 'Wild Turkey', 'Bookers', 'Eagle Rare', \n",
    "                'Buffalo Trace', 'Blantons', 'Four Roses', 'WL Weller',\n",
    "                'Henry McKenna', 'Elijah Craig', 'Old Grand Dad', \n",
    "                'Colonel EH Taylor', 'Makers Mark', 'Woodford Reserve',\n",
    "                'Elmer T Lee', 'Bulleit Bourbon', 'Evan Williams', 'Knob Creek',\n",
    "                'Stagg Jr', 'Russells Reserve', 'Blantons', 'Jack Daniels', \n",
    "                'Bakers', 'Orphan Barrel', 'Jim Beam', 'Larceny', 'Noahs Mill',\n",
    "                'Old Rip Van Winkle', 'Angels Envy', '1792', \n",
    "                'Old Ezra', 'Van Winkle', 'Pappy Van Winkle', 'Michters',\n",
    "                'Heaven Hill', 'George T Stagg', 'Rock Hill Farms', 'Basil Haydens',\n",
    "                'Cabin Still', 'Old Crow', 'Red Stag', 'Fighting Cock', 'JTS Brown',\n",
    "                'Old Fitzgerald', 'Vintage Bourbon',  'Rowans Creek', 'Rebel Yell',\n",
    "                'Willett', 'Ezra Brooks', 'Yellowstone', 'Jeffersons', 'Kentucky Gentleman',\n",
    "                'Kentucky Tavern', 'Kentucky Vintage', 'Ten High', 'Very Old Barton',\n",
    "                'Old Charter', 'Old Taylor', 'George Dickel', 'Virginia Gentleman',\n",
    "                'Old Forester']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4ede19f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a smaller dataframe just to get things to work for the Highland whiskies\n",
    "df_highland = df[(df['region'].str.lower()=='highlands')|(df['region'].str.lower()=='highland')].copy()\n",
    "df_highland['region']='Highland'\n",
    "\n",
    "# List of highland whiskies to use\n",
    "highland_list = ['Aberfeldy', 'AnCnoc', 'Ardmore', 'Ardnamurchan', 'Balblair', 'Ballechin',\n",
    "                  'Banff', 'Ben Nevis', 'Blair Athol', 'Brora', 'Clynelish', 'Dalmore',\n",
    "                  'Dalwhinnie', 'Deanston', 'Edradour', 'Fettercairn', 'Glen Albyn',\n",
    "                  'Glen Deveron', 'Glen Garioch', 'Glen Mhor', 'Glen Ord', 'Glencadam',\n",
    "                  'Glendronach', 'Glenesk', 'Glenglassaugh', 'Glengoyne', 'Glenlochy',\n",
    "                  'Glenmorangie', 'Glenturret', 'Glenugie', 'Glenury Royal', 'Inchmurrin',\n",
    "                  'Knockdhu', 'Loch Lomond', 'McClelland', 'Millburn', 'North Port', 'Oban',\n",
    "                  'Old Pulteney', 'Royal Brackla', 'Royal Lochnagar', 'Tomatin',\n",
    "                  'Tullibardine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7e21c113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a smaller dataframe just to get things to work for the Islands whiskies\n",
    "df_islands = df[(df['region'].str.lower()=='islands')].copy()\n",
    "df_islands['region']='Islands'\n",
    "\n",
    "# list of islands whiskies to use\n",
    "islands_list = ['Arran', 'Highland Park', 'Jura', 'Ledaig', 'Scapa', 'Talisker', 'Tobermory']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b51a3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a smaller dataframe just to get things to work for the Blend whiskies\n",
    "df_blend = df[(df['region'].str.lower()=='blend')|(df['region'].str.lower()=='blends')].copy()\n",
    "df_blend['region']='Blend'\n",
    "\n",
    "# List of Blend whiskies to use\n",
    "blend_list = ['100 Pipers', 'Antiquary', 'Bailie Nicol Jarvie', 'Ballantines', 'Bells',\n",
    "              'Beneagles', 'Black & White', 'Black Bottle', 'Black Dog', 'Buchanans',\n",
    "              'Chivas Regal', 'Clan MacGregor', 'Cutty Sark', 'Dewars', 'Dimple', \n",
    "              'Famous Grouse', 'Glen Turner', 'Grand Old Parr', 'Grants', 'Haig', \n",
    "              'Hankey Bannister', 'Highland Axe', 'J&B', 'Johnnie Walker', \n",
    "              'Passport Scotch', 'Pattisons whisky', 'Pinch', 'Royal Salute', \n",
    "              'Samuel Dow', 'SIA Scotch Whisky', 'Tè Bheag', 'Te Bheag', 'Té Bheag', \n",
    "              'Teachers', 'Vat 69', 'White Horse', 'Whyte & Mackay', 'Angels Nectar', \n",
    "              'Big Peat', 'Monkey Shoulder', 'Poit Dhubh', 'Rock Oyster', 'Scallywag',\n",
    "              'Sheep Dip', 'Timorous Beastie', 'Glenalmond Everyday', 'Mackinlays Shackleton',\n",
    "              'Pigs Nose', 'Compass Box Hedonism', 'Compass Box Great King', 'Compass Box Asyla',\n",
    "              'Compass Box Spice Tree', 'Compass Box Oak Cross', 'Compass Box Peat Monster',\n",
    "              'Compass Box Orangerie', 'Compass Box Phenomenology', 'Black Grouse',\n",
    "              'Compass Box The Lost Blend', 'Compass Box This Is Not a Luxury Whisky',\n",
    "              'Old Perth', 'Compass Box Flaming Heart', 'Compass Box Rivals',\n",
    "              'Compass Box No Name', 'Compass Box The General', 'Compass Box Enlightenment',\n",
    "              'Compass Box 3 Year Old Deluxe', 'Isle of Skye', \n",
    "              'Old St Andrews Clubhouse', 'Naked Grouse', 'Compass Box Juveniles', \n",
    "              'Epitome 24 1993 Maltbarn', 'Compass Box Double Single', \n",
    "              'Compass Box Eleuthera', 'Compass Box Nectar 10th Anniversary',\n",
    "              'Ron Burgundy Scotch', 'Islay Mist', 'Chivas Century'\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fbadf5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a smaller dataframe just to get things to work for the Rye whiskies\n",
    "df_rye = df[df['region'].str.lower()=='rye'].copy()\n",
    "df_rye['region']='Rye'\n",
    "\n",
    "# List of Rye whiskies to use\n",
    "rye_list=['Angels Envy Rye', 'Barrell Rye', 'Bookers Rye', 'Bulleit Rye',\n",
    "        'Colonel EH Taylor Straight Rye', 'George Dickel Rye', 'High West Rye',\n",
    "        'Jeffersons 10 Rye', 'Jim Beam Rye', 'Kentucky Owl Rye', 'Knob Creek Rye',\n",
    "        'Michters 10 Rye', 'Michters Barrel Strength Rye', 'Michters Single Barrel Rye',\n",
    "        'New Riff', 'Old Forester Rye', 'Old Overholt', 'Pikesville', 'Redemption',\n",
    "        'Rittenhouse', 'Russells Reserve Rye', 'Russells Reserve Single Barrel Rye',\n",
    "        'Sazerac', 'Smooth Ambler', 'Thomas H Handy', 'Van Winkle Family Reserve Rye',\n",
    "        'WhistlePig', 'Wild Turkey 101 Rye', 'Willett Family Estate Rye', \n",
    "        'Woodford Reserve Rye',  'Sagamore Spirit Rye', 'James E Pepper']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "77e1d2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a smaller dataframe just to get things to work for the Campbeltown whiskies\n",
    "df_campbeltown = df[(df['region'].str.lower()=='campbeltown')].copy()\n",
    "df_campbeltown['region']='Campbeltown'\n",
    "\n",
    "# list of Campbeltown whiskies to use\n",
    "campbeltown_list = ['Campbeltown', 'Glen Scotia', 'Hazelburn', 'Kilkerran', 'Longrow',\n",
    "                'Springbank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "974454d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a smaller dataframe just to get things to work for the Lowland whiskies\n",
    "df_lowland = df[(df['region'].str.lower()=='lowlands')|(df['region'].str.lower()=='lowland')].copy()\n",
    "df_lowland['region']='Lowland'\n",
    "\n",
    "# List of lowland whiskies to use\n",
    "lowland_list = ['Ailsa Bay', 'Annandale', 'Auchentoshan', 'Bladnoch', 'Daftmill',\n",
    "                'Glenflagler', 'Glenkinchie', 'Inchmurrin', 'Inverleven', 'Kinclaith',\n",
    "                'Ladyburn', 'Littlemill', 'Rosebank', 'St Magdalene']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "37f86cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Canadian whisky dataframe\n",
    "df_canada = df[(df['region'].str.lower()=='canada')].copy()\n",
    "df_canada['region']='Canada'\n",
    "\n",
    "canada_list = ['Alberta', 'Crown Royal', 'Lot No 40', 'JP Wiser', 'Gooderham & Worts',\n",
    "               'Canadian Club', 'Forty Creek', 'Pike Creek', 'Still Waters', \n",
    "               'Glen Breton', 'Pendleton', 'Toronto', 'Shelter Point', 'Mastersons', \n",
    "               'Century Reserve']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "60d8e587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a smaller dataframe just to get things to work for the American whiskies\n",
    "df_america = df[df['region'].str.lower()=='america'].copy()\n",
    "df_america['region']='America'\n",
    "\n",
    "# List of American whiskies to use\n",
    "america_list=['Balcones', 'High West Campfire', 'Mellow Corn', 'Westland', \"Stranahans\",\n",
    "               'High West Bourye', 'High West Son of Bourye', \"Seagrams\", \"McCarthys\",\n",
    "              'George Dickel', 'Wild Turkey Forgiven', 'Barrell Whiskey', \n",
    "              'Bookers Little Book', 'Bully Boy', 'Cut Spike', 'Corsair', \n",
    "              'Woodford Reserve Straight Malt', 'Jack Daniels', 'Smooth Ambler']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cdf91c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a smaller dataframe just to get things to work for the Irish whiskies\n",
    "df_ireland = df[df['region'].str.lower()=='ireland'].copy()\n",
    "df_ireland['region']='Ireland'\n",
    "\n",
    "# List of Irish whiskies to use\n",
    "ireland_list=['Bushmills', 'Connemara', 'Redbreast', 'Jameson', 'Green Spot', \n",
    "              'Teeling', 'Yellow Spot', 'Knappogue Castle', 'Tullamore Dew', 'Tyrconnell',\n",
    "               \"Writers Tears\", 'Irishman', 'Midleton', 'Powers', 'Greenore', 'Kilbeggan',\n",
    "               'Waterford', 'Blue Spot', 'Hinch', 'Glendalough', 'Cooley']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6aa70509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a smaller dataframe just to get things to work for the Japanese whiskies\n",
    "df_japan = df[df['region'].str.lower()=='japan'].copy()\n",
    "df_japan['region']='Japan'\n",
    "\n",
    "# List of Japanese whiskies to use\n",
    "japan_list=['Nikka', 'Yamazaki', 'Hakushu', 'Hibiki', 'Yoichi', 'Akashi', \n",
    "            'Chita', 'Toki', 'Chichibu', 'Ichiros', 'Karuizawa', 'Kirin Fuji Sanroku',\n",
    "            'Kirin Fuji-Sanroku', 'Mars Komagatake', 'Iwai']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d844db6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a smaller dataframe just to get things to work for the Indian whiskies\n",
    "df_india = df[df['region'].str.lower()=='india'].copy()\n",
    "df_india['region']='India'\n",
    "\n",
    "# List of Indian whiskies to use\n",
    "india_list=['Amrut', 'Paul John', 'Adelphi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7ab1dfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a smaller dataframe just to get things to work for the Taiwanese whiskies\n",
    "df_taiwan = df[df['region'].str.lower()=='taiwan'].copy()\n",
    "df_taiwan['region']='Taiwan'\n",
    "\n",
    "# List of Taiwanese whiskies to use\n",
    "taiwan_list=['Kavalan', 'Omar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "18c36f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a smaller dataframe just to get things to work for the Aussie whiskies\n",
    "df_australia = df[df['region'].str.lower()=='australia'].copy()\n",
    "df_australia['region']='Australia'\n",
    "\n",
    "# List of Aussie whiskies to use\n",
    "australia_list=['Heartwood', 'Hellyers Road', 'Sullivans Cove', 'Lime Burners',\n",
    "               'Overeem', 'Bakery Hill', 'Starward', 'Lark', 'Smiths Angaston']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "07dedad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5633 branded successfully. 246 failed. Time taken: 14 seconds.\n",
      "5679 branded successfully. 159 failed. Time taken: 4 seconds.\n",
      "4233 branded successfully. 1066 failed. Time taken: 15 seconds.\n",
      "3864 branded successfully. 245 failed. Time taken: 8 seconds.\n",
      "2103 branded successfully. 23 failed. Time taken: 1 seconds.\n",
      "1278 branded successfully. 392 failed. Time taken: 5 seconds.\n",
      "846 branded successfully. 462 failed. Time taken: 2 seconds.\n",
      "1151 branded successfully. 6 failed. Time taken: 0 seconds.\n",
      "438 branded successfully. 158 failed. Time taken: 0 seconds.\n",
      "425 branded successfully. 147 failed. Time taken: 0 seconds.\n",
      "365 branded successfully. 200 failed. Time taken: 0 seconds.\n",
      "475 branded successfully. 68 failed. Time taken: 0 seconds.\n",
      "461 branded successfully. 43 failed. Time taken: 0 seconds.\n",
      "272 branded successfully. 5 failed. Time taken: 0 seconds.\n",
      "171 branded successfully. 2 failed. Time taken: 0 seconds.\n",
      "119 branded successfully. 11 failed. Time taken: 0 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Empty dataframe to store correctly-branded rows and incorrectly-branded rows\n",
    "df_collated = pd.DataFrame(columns = ['name', 'rating', 'region', 'nose', 'palate', 'finish', 'brand'])\n",
    "df_fails = pd.DataFrame(columns = ['name', 'rating', 'region', 'nose', 'palate', 'finish', 'brand'])\n",
    "\n",
    "# List containing tuples of the names of the dataframes for each region and the corresponding\n",
    "# list for the whisky names in that region\n",
    "region_df_and_lists_tuples = [(df_speyside, speyside_list),\n",
    "                              (df_islay, islay_list),\n",
    "                              (df_bourbon, bourbon_list),\n",
    "                              (df_highland, highland_list),\n",
    "                              (df_islands, islands_list),\n",
    "                              (df_blend, blend_list),\n",
    "                              (df_rye, rye_list),\n",
    "                              (df_campbeltown, campbeltown_list),\n",
    "                              (df_lowland, lowland_list),\n",
    "                              (df_canada, canada_list),\n",
    "                              (df_america, america_list),\n",
    "                              (df_ireland, ireland_list),\n",
    "                              (df_japan, japan_list),\n",
    "                              (df_india, india_list),\n",
    "                              (df_taiwan, taiwan_list),\n",
    "                              (df_australia, australia_list)]\n",
    "\n",
    "def get_brand_names_per_region(region_df_item, df_collated=df_collated, df_fails=df_fails):\n",
    "    '''\n",
    "    INPUTS:\n",
    "    region_df_item - tuple with the regional pandas dataframe as the [0] position, and\n",
    "    the list of whiskies in that region in the [1] position.\n",
    "    df_collated (pandas dataframe) - points to df_collated by default, stores correct ones\n",
    "    df_fails (pandas dataframe) - points to df_fails, where we've failed.\n",
    "    OUTPUTS:\n",
    "    df_collated (pandas dataframe) - points to df_collated by default, stores correct ones\n",
    "    df_fails (pandas dataframe) - points to df_fails, where we've failed.\n",
    "    '''\n",
    "    df = region_df_item[0]\n",
    "    region_list = region_df_item[1]\n",
    "    \n",
    "    # Apply get_match algorithm to fill 'brand' column. Fails are NaNs\n",
    "    df['brand'] = df['name'].apply(lambda x: get_match(x, region_list))\n",
    "\n",
    "    df_collated = pd.concat([df_collated, df[~df['brand'].isnull()]], axis=0)\n",
    "    df_fails = pd.concat([df_fails, df[df['brand'].isnull()]], axis=0)\n",
    "    \n",
    "    return df_collated, df_fails\n",
    "\n",
    "# Iterate through regions:\n",
    "for region_tuple in region_df_and_lists_tuples:\n",
    "    # counters\n",
    "    start_time = time.time()\n",
    "    collatedrows = df_collated.shape[0]\n",
    "    failsrows = df_fails.shape[0]\n",
    "    \n",
    "    # Apply function\n",
    "    df_collated, df_fails = get_brand_names_per_region(region_tuple, df_collated, df_fails)\n",
    "    \n",
    "    print('{} branded successfully. {} failed. '.format(\n",
    "        df_collated.shape[0] - collatedrows, df_fails.shape[0] - failsrows), end=\"\")\n",
    "    print('Time taken: {} seconds.'.format(round(time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7498dace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of corrections to make:\n",
    "brand_corrections = [('1792 Full Proof', '1792'),\n",
    " ('William Larue Weller', 'WL Weller'),\n",
    "('Tè Bheag', 'Té Bheag'),\n",
    "('Te Bheag', 'Té Bheag'),\n",
    "('Michters Barrel Strength Rye','Michters Rye'),\n",
    "(\"Michters 10 Rye\",'Michters Rye'),\n",
    "(\"Michters Single Barrel Rye\",'Michters Rye'),\n",
    "('Russells Reserve Single Barrel Rye','Russells Reserve Rye'),\n",
    "('High West Campfire', 'High West'),\n",
    "('High West Bourye', 'High West'),\n",
    "('High West Son of Bourye', 'High West'),\n",
    "('Kirin Fuji Sanroku', 'Kirin Fuji-Sanroku')   ]\n",
    "\n",
    "for item in brand_corrections:\n",
    "    df_collated.loc[df_collated['brand']==item[0], 'brand'] = item[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1631bf",
   "metadata": {},
   "source": [
    "We have 27,524 items where the brand has been identified. We have 366 brands in total, and these will form the rows of what will be a whisky by tasting note matrix. I was initially intending to to be able to match the specific expression of the whisky rather than merely the brand of whisky, but I can see already that I might be in trouble here. 366 brands is already a lot, and I'm concerned that my classifier is going to struggle.\n",
    "\n",
    "The next task we have to do is to build the list of terms that will form the columns of the matrix. What I need is an algorithm that will iterate through each row and look in the 'nose', 'palate' and 'finish' cells in turn, turning a '0' into a '1' in the matrix whenever it detects a match for a particular adjective - i.e. a CountVectoriser with a custom vocabulary. To create the vocabulary list, I'll first have to apply a word lemmatiser and detect adjectives and other useful taste-related terms (like metaphorical nouns or adverbs), and then go through the list manually. Then, once I have this, I'm in a position to construct a pipeline classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ea2289e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenise_and_stem_text(text):\n",
    "    '''\n",
    "    INPUTS:\n",
    "    text (string) - what you want to be lemmatised\n",
    "    OUTPUTS:\n",
    "    lemmas (list) - list of lemmatised next\n",
    "    '''\n",
    "    # Import stopword list and update with a few of my own\n",
    "    stopword_list = stopwords.words(\"english\")\n",
    "    [stopword_list.append(i) for i in ['nose', 'palate', 'taste', 'finish']]\n",
    "    \n",
    "    # Normalise text - remove numbers too as we don't need them\n",
    "    text = re.sub(r\"[^a-zA-Z]\", \" \", text.lower())\n",
    "    \n",
    "    # tokenise\n",
    "    words = text.split()\n",
    "    \n",
    "    # Checks it's a word and removes stop words\n",
    "    words = [word for word in words if word not in stopword_list]\n",
    "    \n",
    "    # Create stemmer object\n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    # Add lemmas\n",
    "    lemmas = []\n",
    "    for word in words:\n",
    "        lemmas.append(stemmer.stem(word))\n",
    "    \n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b2e2aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for creating custom vocab list (OMG this took ages!!! 15000 word-stems to look through...)\n",
    "\n",
    "#vectoriser = CountVectorizer(tokenizer=tokenise_and_stem_text)\n",
    "#corpus = pd.concat([df_collated['nose'], df_collated['palate'], df_collated['finish']])\n",
    "#X = vectoriser.fit_transform(corpus)\n",
    "\n",
    "#tasting_notes_list = vectoriser.get_feature_names_out().tolist()\n",
    "\n",
    "#i=15\n",
    "#x = 1000 * i\n",
    "#y = x + 1000\n",
    "#print(tasting_notes_list[x:y])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "084fa749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1985"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlist = ['ablaz', 'abnorm', 'abomin', 'abound', 'abras', 'abrupt', 'absinth', 'abuzz',\n",
    "            'acacia', 'accentu', 'access', 'acerb', 'acet', 'aceton', 'acid', 'acidi',\n",
    "            'addict', 'addit', 'adher', 'adhes', 'aerat', 'aflam', 'afterburn',\n",
    "            'aftereffect', 'afterglow', 'aftertas', 'aftertast', 'agreeabl', 'alcohol',\n",
    "            'alcoholburn', 'alcoholi', 'ale', 'alkali', 'alkalin', 'alkaloid', 'allsort',\n",
    "            'allspic', 'allta', 'almond', 'alpin', 'altoid', 'amaretto', 'amaroso',\n",
    "            'ambrosia', 'ameretto', 'americano', 'ammon', 'ammonia', 'ammonium',\n",
    "            'amontillado', 'anaesthetis', 'anchovi', 'angelica', 'anise', 'anisett',\n",
    "            'antifreez', 'antisept', 'appl', 'applecak', 'applejack', 'applejuic',\n",
    "            'applemint', 'applesauc', 'appleskin', 'appleton', 'applewood', 'appley',\n",
    "            'apricot', 'armchair', 'armpit', 'aroma', 'aromaish', 'aromat', 'ash', 'ashen',\n",
    "            'ashphalt', 'ashtray', 'asparagu', 'aspartam', 'asphalt', 'aspirin', 'ass',\n",
    "            'assault', 'assert', 'astonish', 'astound', 'autumn', 'avalanch', 'avocado',\n",
    "            'awak', 'awaken', 'awash', 'bacon', 'baffl', 'bagel', 'baguett', 'bakeappl',\n",
    "            'bakelit', 'baker', 'bakeshop', 'bakewel', 'bamboo', 'banana', 'bananabread',\n",
    "            'band', 'bandag', 'banger', 'banoffe', 'barbecu', 'barbequ', 'barbershop',\n",
    "            'bark', 'barley', 'barli', 'barn', 'barnwood', 'barnyard', 'barnyardi',\n",
    "            'barnyardish', 'basalt', 'basement', 'basil', 'basket', 'basswood', 'bastard',\n",
    "            'bat', 'bath', 'bathroom', 'battenberg', 'batter', 'batteri', 'bazooka', 'bbq',\n",
    "            'bbqed', 'bbqish', 'bbqyness', 'beach', 'beachi', 'beachsid', 'bear',\n",
    "            'bearabl', 'beast', 'beasti', 'beastli', 'beauti', 'bee', 'beebalm', 'beech',\n",
    "            'beechnut', 'beechwood', 'beef', 'beefi', 'beefier', 'beefy', 'beer', 'beeri',\n",
    "            'beerish', 'beeswax', 'beeswaxey', 'beeswaxi', 'beet', 'beetroot', 'bereft',\n",
    "            'berri', 'berry', 'berryfruit', 'big', 'bigger', 'biggest', 'biggish', 'bile',\n",
    "            'bileish', 'billi', 'bin', 'birch', 'biryani', 'biscotti', 'biscuit',\n",
    "            'biscuiti', 'biscuity', 'bite', 'biter', 'bitey', 'biti', 'bitingli', 'bitter',\n",
    "            'bitteress', 'bitteri', 'bitterish', 'bitterli', 'bittermelon', 'bittersweet',\n",
    "            'bitumen', 'black', 'blackberri', 'blackcurr', 'blackpepp', 'blanch', 'blanco',\n",
    "            'bland', 'blander', 'blandest', 'blank', 'blast', 'blaster', 'bleach',\n",
    "            'bleugh', 'bleurgh', 'blitz', 'blizzard', 'block', 'blond', 'bloom', 'blossom',\n",
    "            'blueberri', 'bodied', 'bog', 'boggi', 'boggy', 'bold', 'bolder', 'boldest',\n",
    "            'bombast', 'bomber', 'bombshel', 'bonbon', 'bonfir', 'boost', 'boot', 'booz',\n",
    "            'boozey', 'boozi', 'bore', 'boring', 'borscht', 'bouillon', 'bounc', 'bounci',\n",
    "            'bouquet', 'bourboney', 'bourboni', 'bourbonish', 'boutiqu', 'bovril', 'box',\n",
    "            'boxwood', 'brambl', 'brambleberri', 'bran', 'brandi', 'brandyish', 'brash',\n",
    "            'brasher', 'brashli', 'brasil', 'brass', 'brassi', 'brassier', 'bratwurst',\n",
    "            'braus', 'brawni', 'bread', 'breadcrumb', 'breadfruit', 'breadi', 'breadier',\n",
    "            'breadstick', 'breezey', 'breezi', 'brie', 'brief', 'briefer', 'briefest',\n",
    "            'briefli', 'brighten', 'brighter', 'brighti', 'brightli', 'brillianc',\n",
    "            'brilliant', 'brilliantli', 'brim', 'brimfir', 'brimston', 'brine', 'briney',\n",
    "            'brini', 'brinier', 'brink', 'brioch', 'briquet', 'briquett', 'brisket',\n",
    "            'broad', 'broaden', 'broader', 'broccoli', 'brutal', 'brute', 'brutish',\n",
    "            'bubblegum', 'bubblegummi', 'bubbleyum', 'buckthorn', 'buckwheat', 'burdock',\n",
    "            'burgandi', 'burger', 'burgundi', 'burlap', 'burli', 'burn', 'burner', 'burni',\n",
    "            'burnish', 'burnout', 'burnt', 'burnti', 'burst', 'bursti', 'butter',\n",
    "            'buttercream', 'buttercup', 'butterfat', 'butterfing', 'butterfli',\n",
    "            'buttergeb', 'butteri', 'buttermilk', 'butternut', 'butterscotch',\n",
    "            'butterscotchi', 'buttertart', 'butterworth', 'buttery', 'cacaphoni', 'cacoa',\n",
    "            'cafe', 'cafeteria', 'caff', 'cak', 'cake', 'cakey', 'caki', 'calm', 'calmer',\n",
    "            'calmli', 'camembert', 'campfir', 'campfirey', 'candl', 'candlewax',\n",
    "            'candybar', 'candycan', 'candyfloss', 'candyish', 'cane', 'cannabi',\n",
    "            'cannabisi', 'cantaloup', 'canteloup', 'caocao', 'cappuccino', 'cappucino',\n",
    "            'capuccino', 'caram', 'caramac', 'caramael', 'caramali', 'caramalis',\n",
    "            'carambola', 'caramel', 'caramelis', 'caramelli', 'caramilk', 'cararmel',\n",
    "            'cardamom', 'cardamon', 'cardboard', 'cardboardi', 'carrot', 'cascad',\n",
    "            'cashew', 'casserol', 'caster', 'castor', 'caustic', 'cautious', 'caveman',\n",
    "            'cavern', 'caviar', 'cayann', 'cayen', 'cayenn', 'cedar', 'cedari',\n",
    "            'cedarwood', 'celeri', 'cereal', 'cereali', 'ceris', 'chai', 'chalk',\n",
    "            'chalkboard', 'chalki', 'chalky', 'champignon', 'chanterel', 'chantilli',\n",
    "            'chapati', 'chapstick', 'charcoal', 'charcoali', 'charcuteri', 'chardonnay',\n",
    "            'chargril', 'cheddar', 'chees', 'cheeseburg', 'cheesecak', 'cheesey', 'cheesi',\n",
    "            'cheesiest', 'cheeto', 'chemic', 'chemicali', 'cherri', 'cherry', 'cherrywood',\n",
    "            'chestnut', 'chew', 'chewabl', 'chewey', 'chewi', 'chewier', 'chick',\n",
    "            'chicken', 'chickpea', 'chilli', 'chip', 'chipboard', 'chlorin', 'chlorophyl',\n",
    "            'choc', 'chocol', 'chocolat', 'chocolatey', 'chocolati', 'chorizo', 'chowder',\n",
    "            'churro', 'chutney', 'cider', 'cideri', 'cig', 'cigar', 'cigarello',\n",
    "            'cigarett', 'cilantro', 'cinnabon', 'cinnamint', 'cinnamon', 'cinnamoni',\n",
    "            'cinnamonni', 'cinnamonpowd', 'citric', 'citrisi', 'citron', 'citronella',\n",
    "            'citrus', 'citrusi', 'clean', 'cleaner', 'cleanli', 'clear', 'clearer',\n",
    "            'clearest', 'clementin', 'clobber', 'clove', 'cloy', 'cloyingli', 'club',\n",
    "            'clump', 'clumsi', 'clumsili', 'clung', 'coal', 'coalesc', 'coalsmok', 'coca',\n",
    "            'cocoa', 'coconut', 'coconutti', 'coff', 'coffe', 'coffeebean', 'coffeeshop',\n",
    "            'cognac', 'cointreau', 'coke', 'cold', 'colder', 'coleslaw', 'complex', 'conf',\n",
    "            'confect', 'confection', 'confectionari', 'confectioneri', 'conif', 'conifer',\n",
    "            'conker', 'cool', 'cooler', 'copper', 'copperi', 'cordial', 'cork', 'corn',\n",
    "            'cornbread', 'corndog', 'cornflak', 'cornhusk', 'corni', 'cornichon',\n",
    "            'cornish', 'cornmeal', 'cotton', 'cottoni', 'cottonmouth', 'cottonwood',\n",
    "            'coughdrop', 'crackl', 'cracklin', 'cranberri', 'crap', 'crappi', 'crappier',\n",
    "            'crawfish', 'crayfish', 'crayola', 'crayon', 'cream', 'creamer', 'creami',\n",
    "            'creamier', 'creamiest', 'creamy', 'creol', 'creosot', 'crepe', 'crisco',\n",
    "            'crisp', 'crisper', 'crispi', 'crispiest', 'croissant', 'crumb', 'crumbl',\n",
    "            'crumpet', 'crunch', 'crunchi', 'cucumb', 'cumin', 'cupcak', 'curacao',\n",
    "            'currant', 'curranti', 'current', 'custard', 'custardi', 'daffodil',\n",
    "            'daiquiri', 'damp', 'dampen', 'damper', 'dandelion', 'darjeel', 'dark',\n",
    "            'darken', 'darker', 'darkest', 'darki', 'darkish', 'darkli', 'darksweet',\n",
    "            'date', 'dead', 'decay', 'deceiv', 'deceivingli', 'decompos', 'decoy', 'deep',\n",
    "            'deepen', 'deeper', 'deepest', 'degrad', 'delay', 'delight', 'delish', 'deliv',\n",
    "            'deliveri', 'demerara', 'dental', 'dentist', 'deodor', 'dessert', 'desserti',\n",
    "            'dessic', 'deterg', 'detergenti', 'devoid', 'devolv', 'dextros', 'diaper',\n",
    "            'dick', 'digest', 'digestif', 'dijon', 'diminish', 'dirt', 'dirti', 'dirtier',\n",
    "            'dirty', 'disgust', 'disgustingli', 'dissolv', 'donkey', 'dorito', 'dormant',\n",
    "            'doublemint', 'dough', 'doughi', 'doughier', 'doughnut', 'doughy',\n",
    "            'dragonfruit', 'dri', 'drier', 'driest', 'drift', 'driftwood', 'drizzl',\n",
    "            'drool', 'drumstick', 'dryer', 'dryingli', 'dryish', 'dryli', 'drymouth',\n",
    "            'dryness', 'drywal', 'dull', 'duller', 'dust', 'duster', 'dusti', 'dustier',\n",
    "            'dynam', 'dynamit', 'earth', 'earthen', 'earthi', 'earthier', 'earthy',\n",
    "            'earwax', 'eas', 'easi', 'easier', 'easiest', 'eclair', 'elderberri',\n",
    "            'element', 'elementari', 'elm', 'empti', 'endless', 'endlessli', 'energ',\n",
    "            'energet', 'energi', 'enhanc', 'enigma', 'enigmat', 'ensembl', 'entranc',\n",
    "            'entrench', 'envelop', 'ephemer', 'ephemera', 'epic', 'epicli', 'epoxi',\n",
    "            'epsom', 'espresso', 'ester', 'esterbomb', 'ethanol', 'ethanoli', 'ether',\n",
    "            'ethyl', 'eucalpytu', 'eucalypt', 'eucalyptu', 'eucalyptusi', 'evanesc',\n",
    "            'evapor', 'evapour', 'everpres', 'everywher', 'exact', 'exactli', 'excess',\n",
    "            'expresso', 'faint', 'fainter', 'faintest', 'faintli', 'fair', 'fajita',\n",
    "            'fake', 'familiar', 'fanta', 'farm', 'farmhous', 'farmi', 'farmyard',\n",
    "            'farmyardi', 'fart', 'fat', 'fatter', 'fatti', 'fattier', 'fattiest', 'feast',\n",
    "            'feather', 'featheri', 'featherweight', 'feisti', 'feistier', 'fenugreek',\n",
    "            'ferrero', 'fertil', 'field', 'fig', 'fire', 'firebomb', 'firebreath',\n",
    "            'firepit', 'fireplac', 'firewat', 'firewood', 'firm', 'firmer', 'firmli',\n",
    "            'fisherman', 'fishermen', 'fishi', 'fishiest', 'fishmarket', 'fishmong',\n",
    "            'fizz', 'fizzer', 'fizzi', 'fizzier', 'fizzl', 'flake', 'flakey', 'flaki',\n",
    "            'flamb', 'flambe', 'flamboy', 'flame', 'flammabl', 'flapjack', 'flare',\n",
    "            'flash', 'flashi', 'flat', 'flatbread', 'flatten', 'flatter', 'flattest',\n",
    "            'flavorless', 'flavourful', 'flavoursom', 'flax', 'fleet', 'flesh', 'flint',\n",
    "            'flinti', 'flor', 'flora', 'floral', 'floralhint', 'floralish', 'floss',\n",
    "            'flotsam', 'flour', 'flouri', 'flourish', 'flow', 'flower', 'floweri',\n",
    "            'flowerli', 'fluff', 'fluffi', 'fluid', 'fluidli', 'fluorid', 'flurri',\n",
    "            'flush', 'flutter', 'foam', 'foami', 'focaccia', 'fog', 'foggi', 'foliag',\n",
    "            'fondant', 'fondli', 'fondu', 'foot', 'forest', 'formaldehyd', 'fortifi',\n",
    "            'foul', 'fragran', 'fragranc', 'fragrant', 'fragrantli', 'fraich', 'frais',\n",
    "            'frappuccino', 'fresh', 'fresher', 'freshest', 'frost', 'frosti', 'froth',\n",
    "            'frothi', 'fructos', 'fructosi', 'fruit', 'fruitbread', 'fruitcak',\n",
    "            'fruitcakey', 'fruiter', 'fruiti', 'fruitier', 'fruitiest', 'fruitili', 'fudg',\n",
    "            'fudgesicl', 'fudgi', 'full', 'fuller', 'fulli', 'fungal', 'fungi', 'fungu',\n",
    "            'funk', 'funki', 'funkier', 'funkiest', 'funkish', 'funky', 'gammon', 'garlic',\n",
    "            'gasolin', 'gass', 'gassi', 'gateau', 'gatorad', 'gazpacho', 'gelati',\n",
    "            'gelatin', 'gelato', 'germin', 'gherkin', 'ghost', 'ghosti', 'ghostli', 'gin',\n",
    "            'ginger', 'gingeral', 'gingerbread', 'gingerbreadi', 'gingergread', 'gingeri',\n",
    "            'gingeriest', 'gingernut', 'gingerroot', 'gingersnap', 'ginkgo', 'ginseng',\n",
    "            'ginsengi', 'glaze', 'glucos', 'glue', 'gluey', 'gnarli', 'gooseberri',\n",
    "            'gorgonzola', 'gouda', 'grain', 'graini', 'grainier', 'grainiess', 'grainlik',\n",
    "            'grainy', 'granola', 'granul', 'granular', 'grape', 'grapefru', 'grapefruit',\n",
    "            'grapejuic', 'grapenut', 'grapey', 'grappa', 'grass', 'grassfir', 'grassi',\n",
    "            'grassier', 'grassy', 'gravel', 'gravelli', 'greengag', 'greenhous', 'gristl',\n",
    "            'gristli', 'grit', 'gritti', 'grittier', 'grizzl', 'grizzli', 'ground',\n",
    "            'groundnut', 'guacamol', 'guano', 'guava', 'gum', 'gumbal', 'gumdrop', 'gummi',\n",
    "            'gummibear', 'gummier', 'gunpowd', 'gunpowderi', 'gymsock', 'habanero',\n",
    "            'haddock', 'hairspray', 'ham', 'hammi', 'handbag', 'handsoap', 'handsoapi',\n",
    "            'hardwood', 'haribo', 'harsh', 'harsher', 'harshli', 'hawthorn', 'hay',\n",
    "            'hayish', 'haylik', 'haystack', 'hazelnut', 'hazelnutti', 'heat', 'heather',\n",
    "            'heavi', 'heavier', 'heaviest', 'heft', 'hefti', 'herb', 'herbac', 'herbaci',\n",
    "            'herbal', 'herbali', 'herbi', 'hershey', 'hickori', 'honey', 'honeycak',\n",
    "            'honeycomb', 'honeycrisp', 'honeydew', 'honeygraham', 'honeyish', 'honeymelon',\n",
    "            'honeynut', 'honeysuckl', 'honeysweet', 'hop', 'hoppi', 'hoppy', 'horlick',\n",
    "            'hors', 'horsepiss', 'horseradish', 'horsey', 'hot', 'hotdog', 'hotel',\n",
    "            'hotter', 'hottest', 'huckleberri', 'hulk', 'humidor', 'iceberg', 'icecream',\n",
    "            'innoffens', 'insipid', 'intens', 'intric', 'intricaci', 'intrigu',\n",
    "            'intriguingli', 'invigor', 'iodin', 'iodiney', 'jacket', 'jackfruit', 'jager',\n",
    "            'jagermeist', 'jalapeno', 'jam', 'jambalaya', 'jambon', 'jammi', 'jammier',\n",
    "            'jammy', 'jelli', 'jello', 'jellybean', 'jerk', 'jollyranch', 'juic', 'juicer',\n",
    "            'juicey', 'juici', 'juicier', 'juiciest', 'juicyfruit', 'kahlua', 'kebab',\n",
    "            'kerosen', 'ketchup', 'keton', 'kettlecorn', 'keylim', 'kick', 'kicker',\n",
    "            'kind', 'kinder', 'kipper', 'kipperi', 'kirsch', 'kiwi', 'kiwifruit',\n",
    "            'kiwikiwi', 'kombucha', 'koolaid', 'lacquer', 'lactic', 'lactos', 'lard',\n",
    "            'lardi', 'larg', 'larger', 'largest', 'late', 'latent', 'later', 'latest',\n",
    "            'latex', 'latexi', 'lather', 'layer', 'lazi', 'leaf', 'leafi', 'leafier',\n",
    "            'leak', 'leaki', 'lean', 'leather', 'leatherbound', 'leatheri', 'leatherish',\n",
    "            'leatherwood', 'leek', 'lemon', 'lemonad', 'lemonbread', 'lemoncello',\n",
    "            'lemongrass', 'lemoni', 'lentil', 'lettuc', 'lichen', 'lick', 'lickabl',\n",
    "            'licoric', 'licoricey', 'lifeless', 'light', 'lighter', 'lightest', 'lightish',\n",
    "            'lightweight', 'lilac', 'lime', 'limeston', 'limestoney', 'limestoni', 'limey',\n",
    "            'limon', 'limoncello', 'lindt', 'lint', 'lipstick', 'lipton', 'liqueur',\n",
    "            'liquor', 'listerin', 'liveli', 'loam', 'loami', 'lobster', 'lollipop', 'long',\n",
    "            'longer', 'longest', 'longish', 'lush', 'macadamia', 'macaroni', 'macaroon',\n",
    "            'mace', 'mackerel', 'madeira', 'malt', 'malti', 'maltier', 'maltiest',\n",
    "            'maltman', 'maltodextrin', 'malty', 'mandarin', 'mango', 'maplewood',\n",
    "            'maraschino', 'margarita', 'marigold', 'marijuana', 'marinad', 'marinara',\n",
    "            'maritim', 'maritimey', 'marjoram', 'marlboro', 'marmalad', 'marmit',\n",
    "            'marmiti', 'marsala', 'marsh', 'marshi', 'marshland', 'marshmallow',\n",
    "            'marzipan', 'mascarpon', 'massag', 'massiv', 'matchstick', 'matchsticki',\n",
    "            'mayonnais', 'mcvite', 'mead', 'meadow', 'meadowi', 'meat', 'meatbal', 'meati',\n",
    "            'meatier', 'meaty', 'medal', 'media', 'medic', 'medicin', 'medium',\n",
    "            'mediumish', 'melba', 'mellow', 'mellowest', 'melon', 'melonbread', 'melondew',\n",
    "            'meloni', 'melt', 'melti', 'menthol', 'mentholi', 'metal', 'metali', 'mezcal',\n",
    "            'milk', 'milki', 'milkshak', 'mincemeat', 'mineral', 'minerali', 'mint',\n",
    "            'minti', 'mintier', 'mintish', 'minty', 'mocha', 'moist', 'molass', 'mollusk',\n",
    "            'monster', 'monstrous', 'moonshin', 'morello', 'moscat', 'moss', 'mossi',\n",
    "            'mossier', 'mouthburn', 'mouthtingl', 'muck', 'mud', 'muddi', 'muesli',\n",
    "            'muffin', 'muggi', 'muggier', 'mulberri', 'mulch', 'mulchi', 'multigrain',\n",
    "            'muscat', 'muscatel', 'muscovado', 'muscular', 'museum', 'mush', 'mushi',\n",
    "            'mushroom', 'mushroomi', 'musk', 'muski', 'muskier', 'mustard', 'mustardi',\n",
    "            'musti', 'mustier', 'musty', 'mute', 'mutton', 'naan', 'nacho', 'nailpolish',\n",
    "            'nectar', 'nectari', 'nectarin', 'nesquik', 'new', 'newish', 'nice', 'nickel',\n",
    "            'nicotin', 'nougat', 'nougati', 'novel', 'novelti', 'numb', 'nut', 'nutella',\n",
    "            'nutmeg', 'nutmeggi', 'nutmegi', 'nutrasweet', 'nutrisweet', 'nutt', 'nutti',\n",
    "            'nuttier', 'nutty', 'oak', 'oakey', 'oaki', 'oakier', 'oakiest', 'oakwood',\n",
    "            'oaky', 'oat', 'oatcak', 'oati', 'oatmeal', 'ocean', 'oceani', 'oceansid',\n",
    "            'oil', 'oili', 'oilier', 'oiliest', 'oily', 'ointment', 'old', 'older',\n",
    "            'oldest', 'oldish', 'oolong', 'orang', 'orangejuic', 'orangey', 'orangi',\n",
    "            'orangina', 'orchard', 'orchid', 'oregano', 'outdoorsi', 'overbak',\n",
    "            'overbalanc', 'overblown', 'overcoat', 'overpow', 'overpoweringli',\n",
    "            'overshadow', 'overwhelm', 'overwhelmingli', 'oyster', 'ozon', 'ozoney',\n",
    "            'paint', 'pancak', 'pancetta', 'panetton', 'papaya', 'paprika', 'paraffin',\n",
    "            'parafin', 'parmesan', 'parsley', 'parsnip', 'passionfruit', 'pasta', 'pastel',\n",
    "            'pasti', 'pastrami', 'pastri', 'pate', 'patisseri', 'pavlova', 'pe', 'peach',\n",
    "            'peachi', 'peanut', 'peanuti', 'pear', 'peardrop', 'peat', 'peatbomb',\n",
    "            'peated', 'peathead', 'peati', 'peatier', 'peatiest', 'peatish', 'peatreek',\n",
    "            'peatsmok', 'peaty', 'pecan', 'pecanish', 'pedestrian', 'peel', 'pepp',\n",
    "            'pepper', 'peppercorn', 'pepperi', 'pepperish', 'peppermint', 'pepperminti',\n",
    "            'pepperoni', 'peppery', 'peppi', 'peppier', 'pepsi', 'pepto', 'perfum',\n",
    "            'pernod', 'peroxid', 'pesto', 'petalpetrol', 'petroleum', 'pewter', 'pharmaci',\n",
    "            'pheasant', 'phenol', 'philadelphia', 'pickl', 'pickli', 'pie', 'piecrust',\n",
    "            'pig', 'pimento', 'pina', 'pineappl', 'pineappley', 'pinewood', 'pinot',\n",
    "            'pinotag', 'pipe', 'pipetobacco', 'pistachio', 'pizza', 'plantain', 'planti',\n",
    "            'plastic', 'plastici', 'playdoh', 'playdough', 'pleasant', 'plum', 'plump',\n",
    "            'plywood', 'pommegran', 'pool', 'poop', 'poppadum', 'popsicl', 'poptart',\n",
    "            'porridg', 'porridgey', 'portobello', 'portwood', 'potato', 'potpourri',\n",
    "            'potroast', 'poultri', 'poundcak', 'powder', 'powderi', 'power', 'powerful',\n",
    "            'powerhous', 'prawn', 'pregnant', 'profiterol', 'prosciutto', 'prune',\n",
    "            'pruney', 'pruni', 'pulpi', 'pumpkin', 'punch', 'punchi', 'punchier',\n",
    "            'pungent', 'putrid', 'quirki', 'radish', 'rainfal', 'rainforest', 'raini',\n",
    "            'rainier', 'rainin', 'rainstorm', 'rainwash', 'rainwat', 'raisin', 'raisiney',\n",
    "            'raisini', 'ramen', 'rancid', 'rapid', 'rasp', 'raspberri', 'raspi', 'raw',\n",
    "            'rawer', 'recur', 'redwood', 'reek', 'refresh', 'reincarn', 'reinforc',\n",
    "            'reinvigor', 'relentless', 'reliabl', 'relief', 'relish', 'resin', 'resini',\n",
    "            'rhubarb', 'ribena', 'ricard', 'rice', 'rich', 'richer', 'richest', 'richli',\n",
    "            'ricotta', 'rioja', 'ripe', 'ripen', 'riper', 'risotto', 'roach', 'roast',\n",
    "            'rocket', 'rockmelon', 'romain', 'root', 'rootbeer', 'roquefort', 'rosewood',\n",
    "            'rosi', 'rosin', 'roti', 'rotisseri', 'rotten', 'rough', 'roughen', 'rougher',\n",
    "            'roughli', 'round', 'rounded', 'rounder', 'roundish', 'rubber', 'rubberi',\n",
    "            'rum', 'rumi', 'rumsoak', 'rush', 'rye', 'ryemint', 'ryespic', 'saccharin',\n",
    "            'saccharinni', 'sachet', 'saffron', 'sage', 'sake', 'salami', 'salmon',\n",
    "            'salmoni', 'salsa', 'salt', 'saltdough', 'salti', 'saltier', 'saltiest',\n",
    "            'salty', 'sambuca', 'sandalwood', 'sandlewood', 'sandlewoodyish', 'sangria',\n",
    "            'sapwood', 'sauerkraut', 'sauerkrauti', 'sauna', 'sausag', 'sausagey', 'saute',\n",
    "            'sauvignon', 'savor', 'savori', 'savorli', 'savory', 'savour', 'savouri',\n",
    "            'sawdust', 'sawdusti', 'sawgrass', 'sawmil', 'sawn', 'scallop', 'schnitzel',\n",
    "            'scone', 'scorch', 'scorcher', 'scorchingli', 'scotchi', 'scotchier', 'sea',\n",
    "            'seabass', 'seafoam', 'seafood', 'seafoodi', 'seafoodish', 'seasalt',\n",
    "            'seasmok', 'seaspray', 'seassid', 'seawe', 'seaweedi', 'sediment', 'seed',\n",
    "            'seedi', 'seltzer', 'semisweet', 'semolina', 'sensibl', 'sequoia', 'shale',\n",
    "            'shallow', 'shampoo', 'sharp', 'sharpe', 'sharpen', 'sharper', 'sharpi',\n",
    "            'sharpish', 'shellfish', 'sherbert', 'sherberti', 'sherbet', 'sherbeti',\n",
    "            'sherri', 'sherriest', 'sherrri', 'sherry', 'sherrybomb', 'sherryfruit',\n",
    "            'sherryish', 'sherryland', 'sherrylici', 'sherrynot', 'sherrywood', 'ship',\n",
    "            'shipwreck', 'shiraz', 'shisha', 'shoe', 'shoepolish', 'short', 'shortbread',\n",
    "            'shortcrust', 'shortest', 'shortish', 'shrimp', 'shroom', 'shroomi', 'shrub',\n",
    "            'sickli', 'silk', 'silki', 'silkier', 'simpl', 'sippabl', 'sirloin', 'sizzl',\n",
    "            'skunk', 'skunki', 'slim', 'slimi', 'slipperi', 'sloe', 'sloeberri', 'sloppi',\n",
    "            'slouch', 'slow', 'sludg', 'smog', 'smoke', 'smokei', 'smokepeat', 'smoker',\n",
    "            'smokey', 'smoki', 'smokier', 'smokiest', 'smokish', 'smolder', 'smolderi',\n",
    "            'smooth', 'smoothest', 'smoothi', 'smoothish', 'sneaki', 'soft', 'softest',\n",
    "            'solid', 'soot', 'sooti', 'sophist', 'sorbet', 'souchong', 'souffl', 'soup',\n",
    "            'soupi', 'sour', 'sourdough', 'sourdoughi', 'soya', 'soybean', 'soymilk',\n",
    "            'spearmint', 'spearminti', 'spic', 'spice', 'spicebomb', 'spicebox', 'spicei',\n",
    "            'spicey', 'spici', 'spiciest', 'spicy', 'spikey', 'spiki', 'spiky', 'spinach',\n",
    "            'spongi', 'stableyard', 'stale', 'starburst', 'starfruit', 'steak',\n",
    "            'steakhous', 'steril', 'stew', 'stink', 'stinker', 'stinki', 'strawberri',\n",
    "            'stretch', 'sugar', 'sugarcan', 'sugari', 'sugarloaf', 'sugarplum', 'sugary',\n",
    "            'sulfur', 'sulfuri', 'sulphur', 'sulphuri', 'sultan', 'sultana', 'sultri',\n",
    "            'sumatra', 'sumatran', 'suncream', 'sunkist', 'superglu', 'swamp', 'swampi',\n",
    "            'sweet', 'sweetbread', 'sweetcorn', 'sweetest', 'sweeti', 'sweetshop', 'swell',\n",
    "            'syrup', 'syrupi', 'tabasco', 'taffi', 'tahini', 'talc', 'tamarind', 'tan',\n",
    "            'tandoori', 'tang', 'tangerin', 'tangibl', 'tango', 'tanic', 'tanni', 'tannic',\n",
    "            'tannin', 'tannini', 'taper', 'tapioca', 'tar', 'taragon', 'tarmac',\n",
    "            'tarragon', 'tarri', 'tart', 'tarter', 'tarti', 'tartish', 'tequila',\n",
    "            'teriyaki', 'thick', 'thickest', 'thin', 'thinner', 'thinnest', 'thinnish',\n",
    "            'thyme', 'tikka', 'tingli', 'tingly', 'tiramisu', 'tire', 'tobacco',\n",
    "            'tobaccoish', 'tobleron', 'toffe', 'toffee', 'tortilla', 'trail', 'trailmix',\n",
    "            'tranquil', 'treacl', 'treacley', 'treacli', 'tree', 'treefruit', 'treenut',\n",
    "            'tropicana', 'tropifrutti', 'truffl', 'trunk', 'tubbi', 'tulip', 'tuna',\n",
    "            'turkey', 'turnip', 'turpentin', 'turtlegrass', 'twig', 'twiggi', 'twigi',\n",
    "            'twinki', 'twinkl', 'twizzler', 'tyre', 'umami', 'unapologet', 'unassum',\n",
    "            'unbalanc', 'unctuous', 'underag', 'underbak', 'underbit', 'undercook',\n",
    "            'undergird', 'underproof', 'understat', 'underwhelm', 'undevelop', 'undramat',\n",
    "            'uneven', 'unexcit', 'unimpeach', 'unimpress', 'uninspir', 'unravel',\n",
    "            'unspectacular', 'uplift', 'vagu', 'vaguest', 'valpolicella', 'vanila',\n",
    "            'vanilin', 'vanilla', 'vanillaroot', 'vanilli', 'vanillia', 'vanillin',\n",
    "            'vanish', 'vannila', 'vapor', 'vapour', 'varnish', 'varnishi', 'vaselin',\n",
    "            'veg', 'vegemit', 'veget', 'veggi', 'vegit', 'vegtabl', 'velvet', 'velveti',\n",
    "            'velvetti', 'veneer', 'venison', 'vibrant', 'vigor', 'vigour', 'vinaigrett',\n",
    "            'vindaloo', 'vinegar', 'viney', 'vineyard', 'violent', 'violet', 'viscous',\n",
    "            'vodka', 'voluptu', 'vomit', 'vulgar', 'wafer', 'waffl', 'walnut', 'walnutti',\n",
    "            'wasabi', 'wassail', 'watercress', 'watermelon', 'watermeloni', 'wax', 'waxi',\n",
    "            'waxiest', 'waxless', 'waxy', 'weetabix', 'weighti', 'weird', 'weirdest',\n",
    "            'welli', 'wellington', 'wetsuit', 'whallop', 'wham', 'whammi', 'whamo',\n",
    "            'wheat', 'wheatgrass', 'wheati', 'wheatmeal', 'whimsic', 'whirlwind',\n",
    "            'whitefish', 'wild', 'wildberri', 'windswept', 'wine', 'winegum', 'winey',\n",
    "            'wintermelon', 'wintermint', 'wispi', 'wood', 'woodburn', 'woodchar',\n",
    "            'woodchip', 'wooden', 'woodfir', 'woodglu', 'woodi', 'woodish', 'woodland',\n",
    "            'woodpil', 'woodsap', 'woodsmok', 'woodsmokey', 'woodspic', 'woody', 'wool',\n",
    "            'woolen', 'wooli', 'wormwood', 'yeast', 'yeasti', 'yoghurt', 'yoghurti',\n",
    "            'yogurt', 'yogurti', 'young', 'youngest', 'youngish', 'yum', 'yumm', 'yummi',\n",
    "            'zest', 'zesti', 'zesty', 'zing', 'zinger', 'zingi', 'zombi']\n",
    "len(wordlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9964ddc2",
   "metadata": {},
   "source": [
    "OK, so now I have my overall set of stems that I think are whisky-tasting-related. I got it down from 15000-odd, so it's not too bad. Something I could do here to improve things would be to use a dictionary and start combining some of these stems that are similar in meaning. Another thing I could do is explore different n-gram lengths. I'm using singular n-grams here, but clearly that's reductionistic - e.g. \"peat monster\" means something distinct to \"peat\" + \"monster\" (you can also have sherry monsters). \n",
    "\n",
    "Since I have the tools to set up a vectoriser now, and I have the df_collated dataframe, I consider the data cleaning to be complete. The next notebook will be the construction and tuning of a ML classifier algorithm for predicting the brand of whisky from the nose, palate, and finish notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3ae67d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_collated.to_csv('./data/branded.csv')\n",
    "\n",
    "with open('./data/tasting_notes.txt', 'w') as file:\n",
    "    file.writelines([wordlist[i] + '\\n' for i in range(len(wordlist))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb339b6",
   "metadata": {},
   "source": [
    "Actually... not quite done. Given the rather meagre performance of my classifier algorithm, I decided I'd also try a more selective predictor by restricting things to the domain of single malt scotch whisky to see if it resulted in a better performance. So what follows is a similar bit of code to create a collated list of singlemalts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f2fae345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5633 branded successfully. 246 failed. Time taken: 14 seconds.\n",
      "5679 branded successfully. 159 failed. Time taken: 4 seconds.\n",
      "3864 branded successfully. 245 failed. Time taken: 8 seconds.\n",
      "2103 branded successfully. 23 failed. Time taken: 1 seconds.\n",
      "1151 branded successfully. 6 failed. Time taken: 0 seconds.\n",
      "438 branded successfully. 158 failed. Time taken: 0 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Empty dataframe to store correctly-branded rows and incorrectly-branded rows\n",
    "df_collated = pd.DataFrame(columns = ['name', 'rating', 'region', 'nose', 'palate', 'finish', 'brand'])\n",
    "df_fails = pd.DataFrame(columns = ['name', 'rating', 'region', 'nose', 'palate', 'finish', 'brand'])\n",
    "\n",
    "# List containing tuples of the names of the dataframes for each single malt scothch region \n",
    "# and the corresponding list for the whisky names in that region\n",
    "single_malt_scotch_df_and_lists_tuples = [(df_speyside, speyside_list),\n",
    "                                          (df_islay, islay_list),\n",
    "                                          (df_highland, highland_list),\n",
    "                                          (df_islands, islands_list),\n",
    "                                          (df_campbeltown, campbeltown_list),\n",
    "                                          (df_lowland, lowland_list)]\n",
    "\n",
    "# Iterate through SM scotch regions:\n",
    "for region_tuple in single_malt_scotch_df_and_lists_tuples:\n",
    "    # counters\n",
    "    start_time = time.time()\n",
    "    collatedrows = df_collated.shape[0]\n",
    "    failsrows = df_fails.shape[0]\n",
    "    \n",
    "    # Apply function\n",
    "    df_collated, df_fails = get_brand_names_per_region(region_tuple, df_collated, df_fails)\n",
    "    \n",
    "    print('{} branded successfully. {} failed. '.format(\n",
    "        df_collated.shape[0] - collatedrows, df_fails.shape[0] - failsrows), end=\"\")\n",
    "    print('Time taken: {} seconds.'.format(round(time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1f37f13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_collated.to_csv('./data/branded_singlemalts.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
